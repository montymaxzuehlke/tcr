#!/usr/bin/python3

import sys
import shutil
import os
from os.path import expanduser
HOME = expanduser("~") #if needed; provides home directory of current user
DEFAULT_ORIGIN = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.abspath(DEFAULT_ORIGIN + "/Utils/"))


#########################################################
######################### H2O ###########################
#########################################################
import h2o
from h2o.automl import H2OAutoML
from h2o.estimators.xgboost import H2OXGBoostEstimator

#########################################################
####################### General #########################
#########################################################

import sklearn.model_selection
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
import numpy as np
import multiprocessing
import random
import pickle
import time
from sklearn.feature_selection import SelectFromModel
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

import pipeline_functions
import dataset_provider


################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################




"""
###
BEGINNING OF SCRIPT
###
"""





################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################








def main():

    ARGS = sys.argv[1:]
    print("\n")
    print("ARGS:", ARGS)
    print("\n")

    
    """
    <<<
    AUTOML PIPELINE
    >>>
    """
    
    ######################################################################################################################################################################################################
    ######################################################################################################################################################################################################
    ######################################################################################################################################################################################################

    SET_NAME = ARGS[0] 
    ITERATOR = int(ARGS[1]) 

    VERBOSE = True #Good to trace everything 

    TMP_DIRECTORY = DEFAULT_ORIGIN + "/automl/" + SET_NAME + "/" + str(ITERATOR)
    DEFAULT_DIRECTORY = DEFAULT_ORIGIN + "/Results_REF/"
    MODEL_DIRECTORY = DEFAULT_ORIGIN + "/H2O_Processing/" 

    #intra box
    #ROBUSTNESS_DIRECTORY = DEFAULT_ORIGIN 

    #home directory
    ROBUSTNESS_DIRECTORY = DEFAULT_ORIGIN + "/Processing/"

    if not os.path.exists(TMP_DIRECTORY):
        os.mkdir(TMP_DIRECTORY)
    
    h2o.init(name="C-"+TMP_DIRECTORY, ice_root=TMP_DIRECTORY, log_dir=TMP_DIRECTORY, max_mem_size="8G") #rest of RAM goes to XGBoost // increase the 8G if the dataset is VERY large

        
           


    
    
    
################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################




    """
    ###
    LOADING AND RESCALING DATASET
    ###
    """




################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################
    

    
    """
    ***
    DATASET
    ***
    """
    
    
    SET_HANDLE, X, y, NR_BINS = dataset_provider.dataset_decision(SET_NAME) #see dedicated script
    
    LEN_ALL = len(X)
    
    print("Set used:", SET_NAME, NR_BINS)
    print()
    print("Random seed for this run:", ITERATOR)
    print()

    if VERBOSE:

        print()
        print("Dataset-Example 0:", X[0])
        print("Dataset-Example 1:", X[1])
        print("Dataset-Example 2:", X[2])
        print()

        print()
        print("Label-Example 0:", y[0])
        print("Label-Example 1:", y[1])
        print("Label-Example 2:", y[2])
        print()
    
    print("Normalising Dataset and Labels:")
    print()

    #Normalising:
    DATA_SCALER = MinMaxScaler()
    X = DATA_SCALER.fit_transform(X)  
    LABEL_SCALER = MinMaxScaler()
    y = LABEL_SCALER.fit_transform(y)  

    # see: https://stackoverflow.com/questions/29438265/stratified-train-test-split-in-scikit-learn

    REG_BINS = np.quantile(y, np.linspace(start=1/NR_BINS, stop=1, num=NR_BINS))
    print("Bin Thresholds:", np.linspace(start=1/NR_BINS, stop=1, num=NR_BINS))
    print()
    print("Quantiles according to NR_BINS:", REG_BINS)
    print()
    y_binned = np.digitize(y.copy(), REG_BINS, right=True)

    ABD = [0]*NR_BINS
    for i in range(len(y_binned)):
        ABD[y_binned[i][0]] += 1
    print("Absolute Bin Distribution:", ABD)
    print()

    ###for plotting purposes:

    BINS = [np.min(y)]
    for i in range(NR_BINS):
        BINS.append(REG_BINS[i])

    print("BINS:", BINS)


        
        

    if VERBOSE:

        print()
        print("Normalised Dataset-Example 0:", X[0])
        print("Normalised Dataset-Example 1:", X[1])
        print("Normalised Dataset-Example 2:", X[2])
        print()

        print()
        print("(Normalised) Label-Example 0:", y[0])
        print("(Normalised) Label-Example 1:", y[1])
        print("(Normalised) Label-Example 2:", y[2])
        print()    


    

    
    
    
    
    




################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################




    """
    ###
    BEGINNING OF DATA PREPROCESSING
    ###
    """




################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################




    print("Starting Timer:")
    print()
    start = time.time()
    

    #from sklearn: Allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes.
    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, stratify=y_binned, random_state=ITERATOR) #starting with a train/test split of 4:1; will later produce 3 parts training set, 1 part proxy-validation set and 1 part test set (see below)

    len_train = len(X_train)
    len_train_half = len_train // 2
    len_test = len(X_test)
    len_test_half = len_test // 2

    X_train = np.array(X_train, dtype="float32")
    X_test = np.array(X_test, dtype="float32")

    NR_OF_FEATURES = len(X_train[0])
    print("NR_OF_FEATURES:", NR_OF_FEATURES)
    print()

    y_train = np.array(y_train, dtype="float32")
    y_test = np.array(y_test, dtype="float32")
  
    print()
    print("X_train.shape, y_train.shape (still including validation data):", X_train.shape, y_train.shape)
    print("X_test.shape, y_test.shape:", X_test.shape, y_test.shape)
    print()



      
################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################




    """
    ###
    LOADING ROBUSTNESS VALUES 
    ###
    """




################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################
           
            

    with open(ROBUSTNESS_DIRECTORY + SET_NAME + '/train_rob_vals_' + str(ITERATOR) + '.pickle', 'rb') as f:
        train_rob_vals = pickle.load(f)
    with open(ROBUSTNESS_DIRECTORY + SET_NAME + '/train_indices_ordered_' + str(ITERATOR) + '.pickle', 'rb') as f:
        train_indices_ordered = pickle.load(f)


    with open(ROBUSTNESS_DIRECTORY + SET_NAME + '/test_rob_vals_' + str(ITERATOR) + '.pickle', 'rb') as f:
        test_rob_vals = pickle.load(f)
    with open(ROBUSTNESS_DIRECTORY + SET_NAME + '/test_indices_ordered_' + str(ITERATOR) + '.pickle', 'rb') as f:
        test_indices_ordered = pickle.load(f)




################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################
    
    X_test = X_test[test_indices_ordered]    
    y_test = y_test[test_indices_ordered]
    
    #order training data w.r.t. robustness values
    X_train = X_train[train_indices_ordered]    
    y_train = y_train[train_indices_ordered]
    
    #repeating this step will lead to the same "randomly" distributed arrays
    X_train = X_train[train_indices_ordered]
    y_train = y_train[train_indices_ordered]
  
    #for h2o compatibility        
    columns_X = ["c"+str(k) for k in range(NR_OF_FEATURES)]
    columns_y = ["target"]    
    
    TRAINING_FRAME = h2o.H2OFrame(np.concatenate([X_train, y_train], axis=1), column_names=columns_X+columns_y)
    TEST_FRAME = h2o.H2OFrame(np.concatenate([X_test, y_test], axis=1), column_names=columns_X+columns_y)


    #saving original labels for evaluation later
    with open(DEFAULT_DIRECTORY + SET_NAME + "/" + str(ITERATOR) + "_" + "test_set_labels.pickle", 'wb') as f:
        pickle.dump(y_test, f)   
      
    if VERBOSE:
        print("TRAINING_FRAME.head()", TRAINING_FRAME.head())
        print()
        print("TEST_FRAME.head()", TEST_FRAME.head())
        print()

            
################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################        
                    
    automl = H2OAutoML(
                       max_runtime_secs=3*3600, 
                       max_models=1,
                       stopping_rounds=10, 
                       preprocessing=[], #to disable preprocessing
                       nfolds=5,
                       exploitation_ratio=0.1,
                       stopping_metric="MAE", 
                       include_algos=["XGBoost"],
                       seed=ITERATOR
                      )
            


################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

    stopwatch = time.time() 

    automl.train(x=columns_X, y="target", training_frame=TRAINING_FRAME)

    stopwatch_click = time.time() - stopwatch

    with open(MODEL_DIRECTORY + SET_NAME + "/" +"comp_time_" + str(ITERATOR) + ".pickle", 'wb') as f:
        pickle.dump(stopwatch_click, f)
    
    print()
    print("Training completed!")
    print()

    if VERBOSE:
        lb = automl.leaderboard
        print(lb.head(rows=lb.nrows)) 

    #Predicting    
    test_set_predictions = np.array(automl.predict(TEST_FRAME).as_data_frame(use_pandas=True, header=False))    
    if VERBOSE:
        print("test_set_predictions:", test_set_predictions)

    with open(DEFAULT_DIRECTORY + SET_NAME + "/" + str(ITERATOR) + "_REFERENCE_" + "test_set_predictions.pickle", 'wb') as f:
        pickle.dump(test_set_predictions, f)

    




################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################



    model_ids = list(automl.leaderboard['model_id'].as_data_frame().iloc[:,0]) #model ids
    h2oModelD = h2o.get_model([mid for mid in model_ids if "XGBoost" in mid][0]) #leader model
    nativeXGBoostParamDict = h2oModelD.convert_H2OXGBoostParams_2_XGBoostParams()
    if VERBOSE:
        print("nativeXGBoostParamDict", nativeXGBoostParamDict)
    with open(MODEL_DIRECTORY + SET_NAME + "/" + str(ITERATOR) + "_" + "nativeXGBoostParamDict.pickle", 'wb') as f:
        pickle.dump(nativeXGBoostParamDict, f) 

    nativeXGBoostInput_TRAINING = TRAINING_FRAME.convert_H2OFrame_2_DMatrix(columns_X, "target", h2oModelD)
    nativeXGBoostInput_PREDICTION = TEST_FRAME.convert_H2OFrame_2_DMatrix(columns_X, "target", h2oModelD)

    nativeXGBoostInput_TRAINING.save_binary(MODEL_DIRECTORY + SET_NAME + "/" + str(ITERATOR) + "_" + "nativeXGBoostInput_TRAINING.buffer")
    nativeXGBoostInput_PREDICTION.save_binary(MODEL_DIRECTORY + SET_NAME + "/" + str(ITERATOR) + "_" + "nativeXGBoostInput_PREDICTION.buffer")




################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################

################################################################################################################################################################################################################################################
################################################################################################################################################################################################################################################


    print()
    print("Finished!!!", "Time Elapsed:", round(time.time()-start, 2), "Secs")
    print()

    shutil.rmtree(TMP_DIRECTORY, ignore_errors=True)
    print()
    print("Deleted '%s' directory successfully" % TMP_DIRECTORY)
    print()

if __name__ == '__main__':
    print("Starting Pipeline")
    print()
    main()
    print("The End")
    print()


